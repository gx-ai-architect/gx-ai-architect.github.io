<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Personal website of Guangxuan Xu - Principal Research Scientist">
    <title>Guangxuan Xu - AI/ML Research Scientist</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <div class="nav-content">
                <a href="#" class="logo">Guangxuan Xu</a>
                <ul class="nav-links">
                    <li><a href="#about">About</a></li>
                    <li><a href="#experience">Experience</a></li>
                    <li><a href="#projects">Projects</a></li>
                    <li><a href="#skills">Skills</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <main>
        <section id="hero" class="hero">
            <div class="container">
                <div class="hero-content">
                    <img src="profile.jpg" alt="Profile Picture" class="profile-pic" id="profile-pic">
                    <h1>Guangxuan Xu</h1>
                    <p class="title">Principal Research Scientist | AI/ML Researcher</p>
                    <p class="location">Somerville, MA</p>
                    <div class="social-links">
                        <a href="https://github.com/gx-ai-architect" target="_blank" rel="noopener">GitHub</a>
                        <a href="https://www.linkedin.com/in/gxxu/" target="_blank" rel="noopener">LinkedIn</a>
                        <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar</a>
                        <a href="mailto:gxu21@cs.ucla.edu">Email</a>
                    </div>
                </div>
            </div>
        </section>

        <section id="about" class="section">
            <div class="container">
                <h2>About</h2>
                <p class="about-text">
                    I am a Principal Research Scientist at Red Hat, where I lead the design and development of enterprise-grade AI agent systems and post-training of large language models. My research focuses on inference-time scaling, preference alignment, and building robust AI systems for enterprise applications. I am a core contributor and architect for agent evaluation frameworks and have pioneered novel methods for automatic preference annotation that significantly reduce human labeling costs.
                </p>
                <p class="about-text">
                    My work has been published at top-tier venues including NeurIPS, ICLR, ICML, ACL, and EMNLP. I hold an MS in Computer Science from UCLA and a BA in Computer Science and Government from Wesleyan University. Previously, I was a Research Engineer at IBM Research, where I led the development of Merlinite-7B-PT, the first preference-aligned LLM from the InstructLab project, and contributed to foundational research in LLM alignment and reasoning.
                </p>
            </div>
        </section>

        <section id="news" class="section section-alt">
            <div class="container">
                <h2>Recent Updates</h2>
                <ul class="news-list">
                    <li>
                        <span class="date">Jan 2025</span>
                        <span class="news-item">Paper on "Dr. SoW: Density Ratio of Strong-over-Weak LLMs for Preference Tuning" released on arXiv</span>
                    </li>
                    <li>
                        <span class="date">Nov 2024</span>
                        <span class="news-item">Promoted to Principal Research Scientist at Red Hat, Inc.</span>
                    </li>
                    <li>
                        <span class="date">Sep 2024</span>
                        <span class="news-item">Paper accepted to NeurIPS 2024: "Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods"</span>
                    </li>
                    <li>
                        <span class="date">Sep 2024</span>
                        <span class="news-item">Paper accepted to ICLR 2025: "Unveiling the Secret Recipe: A Guide for Supervised Fine-Tuning Small LLMs"</span>
                    </li>
                    <li>
                        <span class="date">May 2024</span>
                        <span class="news-item">Paper accepted to Findings of ACL 2024: "A Grounded Preference Model for LLM Alignment"</span>
                    </li>
                </ul>
            </div>
        </section>

        <section id="experience" class="section">
            <div class="container">
                <h2>Experience</h2>
                <div class="experience-item">
                    <h3>Principal Research Scientist</h3>
                    <p class="company">Red Hat, Inc. | Boston, MA</p>
                    <p class="period">November 2024 - Present</p>
                    <ul class="description">
                        <li>Led design and development of enterprise-grade agent system within IBM's WatsonX Orchestrate. Core contributor and architect for agent evaluation and feedback loop.</li>
                        <li>Spearheaded integration of inference-time scaling and reward modeling techniques into production stack, enabling agents to learn from evaluation results and improve through compute scaling and reinforcement learning.</li>
                        <li>Led preference training for RHELAI â€“ a flagship AI product for IBM and Red Hat. Invented Dr.SoW, a novel method for automatic preference annotation that significantly reduces human labeling cost.</li>
                        <li>Co-invented particle-based sampling algorithm for efficient LLM inference-time compute scaling, achieving state-of-the-art accuracy-compute tradeoffs.</li>
                    </ul>
                </div>
                <div class="experience-item">
                    <h3>Research Engineer</h3>
                    <p class="company">IBM Research, Thomas J. Watson Research Center | Yorktown Heights, NY</p>
                    <p class="period">January 2023 - November 2024</p>
                    <ul class="description">
                        <li>Led development and release of Merlinite-7B-PT, the first preference-aligned LLM from the InstructLab project, achieving alignment performance competitive with GPT-3.5 and Claude-v1 using only 48k AI-generated preference pairs.</li>
                        <li>Developed reward modeling techniques with document-grounded feedback to improve faithfulness and reasoning in QA and RAG tasks.</li>
                        <li>Co-developed Bayesian framework for preference alignment included in technical reports of Nvidia's Nemotron series and IBM's Granite models.</li>
                    </ul>
                </div>
                <div class="experience-item">
                    <h3>AI Research Intern</h3>
                    <p class="company">IBM Research, Thomas J. Watson Research Center | Yorktown Heights, NY</p>
                    <p class="period">June 2022 - September 2022</p>
                    <ul class="description">
                        <li>Improved training of IBM's SOTA BART-based AMR parser with dynamic MLM and features creation, reducing training time by 20% and memory requirement by 130G.</li>
                        <li>Led development of first jointly-trained text and AMR-graph model with novel constrained decoding scheme, approaching SOTA Smatch scores.</li>
                    </ul>
                </div>
                <div class="experience-item">
                    <h3>Graduate Research Assistant</h3>
                    <p class="company">PLUS Lab, UCLA | Los Angeles, CA</p>
                    <p class="period">September 2021 - Present</p>
                    <ul class="description">
                        <li>Led development of NECE (Narrative Event Chain Extraction) toolkit, building first online interactive system dedicated to narrative event chain analysis with 10% performance improvement.</li>
                        <li>Proposed first human-reaction based model to evaluate dialogue engagingness, surpassing existing metrics in 4 of 5 benchmarks.</li>
                        <li>Applied knowledge distillation and attention head pruning to reduce toxicity-level of GPT2 and Blenderbot, reducing memory by 50% and inference time by 60%.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="projects" class="section section-alt">
            <div class="container">
                <h2>Selected Projects & Publications</h2>
                <div class="projects-grid">
                    <div class="project-card">
                        <h3>Dr. SoW: Preference Tuning</h3>
                        <p class="project-description">Novel method for automatic preference annotation using density ratio of strong-over-weak LLMs, significantly reducing human labeling costs in LLM alignment. (arXiv 2025)</p>
                        <div class="project-links">
                            <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank">Paper</a>
                        </div>
                    </div>
                    <div class="project-card">
                        <h3>Inference-Time Scaling via Particle Methods</h3>
                        <p class="project-description">Particle-based Monte Carlo sampling algorithm for efficient LLM inference-time compute scaling, achieving SOTA accuracy-compute tradeoffs. (NeurIPS 2024)</p>
                        <div class="project-links">
                            <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank">Paper</a>
                        </div>
                    </div>
                    <div class="project-card">
                        <h3>Merlinite-7B-PT</h3>
                        <p class="project-description">First preference-aligned LLM from InstructLab project, achieving GPT-3.5 level performance using only 48k AI-generated preference pairs. Released open-source under Apache 2.0.</p>
                        <div class="project-links">
                            <a href="https://huggingface.co/" target="_blank">HuggingFace</a>
                        </div>
                    </div>
                    <div class="project-card">
                        <h3>NECE: Narrative Event Chain Extraction</h3>
                        <p class="project-description">First online interactive system for narrative event chain analysis, combining BookNLP and AllenNLP with novel algorithms for character extraction and salient event identification.</p>
                        <div class="project-links">
                            <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank">Website</a>
                        </div>
                    </div>
                    <div class="project-card">
                        <h3>BRAIn: Bayesian Preference Alignment</h3>
                        <p class="project-description">Bayesian framework for LLM preference alignment adopted by Nvidia's Nemotron and IBM's Granite models. Reward-conditioned amortized inference for natural language generation. (ICML 2024)</p>
                        <div class="project-links">
                            <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank">Paper</a>
                        </div>
                    </div>
                    <div class="project-card">
                        <h3>EnDex: Dialogue Engagingness Evaluation</h3>
                        <p class="project-description">First human-reaction based model for evaluating dialogue engagingness at scale, trained on large Reddit corpus using distant-supervision framework. (EMNLP 2022)</p>
                        <div class="project-links">
                            <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank">Paper</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="skills" class="section">
            <div class="container">
                <h2>Skills & Technologies</h2>
                <div class="skills-grid">
                    <div class="skill-category">
                        <h3>AI/ML Frameworks</h3>
                        <p>PyTorch, Spark, Pandas, Machine Learning, Deep Learning, NLP, LLM Alignment, Reinforcement Learning</p>
                    </div>
                    <div class="skill-category">
                        <h3>Developer Tools</h3>
                        <p>Python, Git, Docker, OpenShift, Cursor, ClaudeCode, SQLite</p>
                    </div>
                    <div class="skill-category">
                        <h3>Research Areas</h3>
                        <p>Inference-Time Scaling, Preference Alignment, Bayesian Inference, Reward Modeling, Dialogue Systems, Knowledge Distillation</p>
                    </div>
                    <div class="skill-category">
                        <h3>Specializations</h3>
                        <p>Large Language Models, Enterprise AI Agents, Post-Training Techniques, Document-Grounded Feedback, RAG Systems</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="contact" class="section section-alt">
            <div class="container">
                <h2>Contact</h2>
                <p class="contact-text">
                    I'm always interested in new research collaborations and opportunities. Feel free to reach out to discuss AI/ML research, enterprise AI systems, or potential collaborations.
                </p>
                <div class="contact-info">
                    <p><strong>Email:</strong> <a href="mailto:gxu21@cs.ucla.edu">gxu21@cs.ucla.edu</a></p>
                    <p><strong>GitHub:</strong> <a href="https://github.com/gx-ai-architect" target="_blank">@gx-ai-architect</a></p>
                    <p><strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/gxxu/" target="_blank">linkedin.com/in/gxxu</a></p>
                    <p><strong>Google Scholar:</strong> <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en" target="_blank">Publications</a></p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; <span id="year"></span> Guangxuan Xu. All rights reserved.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
